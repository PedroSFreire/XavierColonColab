{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Code to train nnUnet V1"
      ],
      "metadata": {
        "id": "ZD7f-FM6Xuui"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3Jm8YYD4Z6p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from collections import OrderedDict\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "hWGZtfdr4bkG",
        "outputId": "a476535c-f7d1-47d8-9f56-5ec11c10c57e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnunet\n",
            "  Downloading nnunet-1.7.1.tar.gz (276 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/276.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m276.5/276.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.6/276.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>1.10.0 in /usr/local/lib/python3.10/dist-packages (from nnunet) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nnunet) (4.66.5)\n",
            "Collecting dicom2nifti (from nnunet)\n",
            "  Downloading dicom2nifti-2.4.11-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: scikit-image>=0.14 in /usr/local/lib/python3.10/dist-packages (from nnunet) (0.23.2)\n",
            "Collecting medpy (from nnunet)\n",
            "  Downloading medpy-0.5.2.tar.gz (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.3/156.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nnunet) (1.13.1)\n",
            "Collecting batchgenerators>=0.23 (from nnunet)\n",
            "  Downloading batchgenerators-0.25.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nnunet) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nnunet) (1.3.2)\n",
            "Collecting SimpleITK (from nnunet)\n",
            "  Downloading SimpleITK-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nnunet) (2.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nnunet) (2.32.3)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from nnunet) (5.0.1)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (from nnunet) (2024.7.24)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from nnunet) (3.7.1)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.23->nnunet) (9.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.23->nnunet) (1.0.0)\n",
            "Collecting unittest2 (from batchgenerators>=0.23->nnunet)\n",
            "  Downloading unittest2-1.1.0-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.23->nnunet) (3.5.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14->nnunet) (3.3)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14->nnunet) (2.34.2)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14->nnunet) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14->nnunet) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>1.10.0->nnunet) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>1.10.0->nnunet) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>1.10.0->nnunet) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>1.10.0->nnunet) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>1.10.0->nnunet) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>1.10.0->nnunet)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>1.10.0->nnunet)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>1.10.0->nnunet)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>1.10.0->nnunet)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>1.10.0->nnunet)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>1.10.0->nnunet)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>1.10.0->nnunet)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>1.10.0->nnunet)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>1.10.0->nnunet)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>1.10.0->nnunet)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>1.10.0->nnunet)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>1.10.0->nnunet) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>1.10.0->nnunet)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting pydicom>=2.2.0 (from dicom2nifti->nnunet)\n",
            "  Downloading pydicom-2.4.4-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting python-gdcm (from dicom2nifti->nnunet)\n",
            "  Downloading python_gdcm-3.0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunet) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunet) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunet) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunet) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunet) (2.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->nnunet) (71.0.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nnunet) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nnunet) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nnunet) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nnunet) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nnunet) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nnunet) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nnunet) (1.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->nnunet) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>1.10.0->nnunet) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>1.10.0->nnunet) (1.3.0)\n",
            "Collecting argparse (from unittest2->batchgenerators>=0.23->nnunet)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting traceback2 (from unittest2->batchgenerators>=0.23->nnunet)\n",
            "  Downloading traceback2-1.4.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting linecache2 (from traceback2->unittest2->batchgenerators>=0.23->nnunet)\n",
            "  Downloading linecache2-1.0.0-py2.py3-none-any.whl.metadata (1000 bytes)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading dicom2nifti-2.4.11-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m112.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SimpleITK-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydicom-2.4.4-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_gdcm-3.0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: nnunet, batchgenerators, medpy\n",
            "  Building wheel for nnunet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nnunet: filename=nnunet-1.7.1-py3-none-any.whl size=531261 sha256=f1c7c7364ff47750868cb90c4356635683ff85d7956dce2d4d4bbd14d395f145\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/21/5a/48b9c7298aa4ea109aafb375f8e97b67c5b0921fa533672fd0\n",
            "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgenerators: filename=batchgenerators-0.25-py3-none-any.whl size=89008 sha256=377f7135eaea2d1d90c37d41e89919ed5f7bed344670458db26adfa4019a7581\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/b0/1b/40912fb58eb167b86cbc444ddb2e6ba382b248215295f932e2\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for medpy: filename=MedPy-0.5.2-cp310-cp310-linux_x86_64.whl size=762840 sha256=db3af05895de6f4776ec13f75ef2c9ff87556adb6276281f29e0222586d85f97\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b8/63/bdf557940ec60d1b8822e73ff9fbe7727ac19f009d46b5d175\n",
            "Successfully built nnunet batchgenerators medpy\n",
            "Installing collected packages: SimpleITK, linecache2, argparse, traceback2, python-gdcm, pydicom, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, unittest2, nvidia-cusparse-cu12, nvidia-cudnn-cu12, medpy, dicom2nifti, nvidia-cusolver-cu12, batchgenerators, nnunet\n",
            "Successfully installed SimpleITK-2.3.1 argparse-1.4.0 batchgenerators-0.25 dicom2nifti-2.4.11 linecache2-1.0.0 medpy-0.5.2 nnunet-1.7.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 pydicom-2.4.4 python-gdcm-3.0.24.1 traceback2-1.4.0 unittest2-1.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              },
              "id": "fac2a50cc49844f78d46a6288f798822"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install nnunet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXz8Esf94qOd",
        "outputId": "b1c3712f-7784-408b-8780-eeec2eacb732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Please cite the following paper when using nnUNet:\n",
            "\n",
            "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
            "\n",
            "\n",
            "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import nnunet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7TA1qYbs88x"
      },
      "source": [
        "#Mount Drive and prep folders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYJ3ZqLGtA4k",
        "outputId": "5a41ad32-d9d7-436b-e8e1-f55711ebcbcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount = True)\n",
        "\n",
        "drive_dir = \"/content/drive/My Drive\"\n",
        "mount_dir = os.path.join(drive_dir, \"Colab\")\n",
        "base_dir = os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZXXYYAhzF3r"
      },
      "outputs": [],
      "source": [
        "#create folders\n",
        "def make_if_dont_exist(folder_path,overwrite=False):\n",
        "    \"\"\"\n",
        "    creates a folder if it does not exists\n",
        "    input:\n",
        "    folder_path : relative path of the folder which needs to be created\n",
        "    over_write :(default: False) if True overwrite the existing folder\n",
        "    \"\"\"\n",
        "    if os.path.exists(folder_path):\n",
        "\n",
        "        if not overwrite:\n",
        "            print(f\"{folder_path} exists.\")\n",
        "        else:\n",
        "            print(f\"{folder_path} overwritten\")\n",
        "            shutil.rmtree(folder_path)\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "    else:\n",
        "      os.makedirs(folder_path)\n",
        "      print(f\"{folder_path} created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1_FOATSQj9M"
      },
      "source": [
        "#Environment Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IQtTXKlVXrch"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVleR-yZQvsh",
        "outputId": "0274eadb-892e-4d59-bd09-42bdd1dd7991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory /content\n",
            "/content/drive/My Drive/Colab/nnUNet_raw exists.\n",
            "/content/drive/My Drive/Colab/nnUNet_preprocessed exists.\n",
            "/content/drive/My Drive/Colab/RESULTS_FOLDER exists.\n",
            "/content/drive/My Drive/Colab/RawData exists.\n",
            "If No Error Occured Continue Forward. =)\n"
          ]
        }
      ],
      "source": [
        "print(\"Current Working Directory {}\".format(os.getcwd()))\n",
        "path_dict = {\n",
        "    \"nnUNet_raw_data_base\" : os.path.join(mount_dir, \"nnUNet_raw\"),\n",
        "    \"nnUNet_preprocessed\" : os.path.join(mount_dir, \"nnUNet_preprocessed\"), # 1 experiment: 1 epoch took 112s\n",
        "    \"RESULTS_FOLDER\" : os.path.join(mount_dir, \"RESULTS_FOLDER\"),\n",
        "    \"RAW_DATA_PATH\" : os.path.join(mount_dir, \"RawData\"), # This is used here only for convenience (not necessary for nnU-Net)!\n",
        "}\n",
        "\n",
        "\n",
        "# Write paths to environment variables\n",
        "for env_var, path in path_dict.items():\n",
        "  os.environ[env_var] = path\n",
        "\n",
        "# Check whether all environment variables are set correct!\n",
        "for env_var, path in path_dict.items():\n",
        "  if os.getenv(env_var) != path:\n",
        "    print(\"Error:\")\n",
        "    print(\"Environment Variable {} is not set correctly!\".format(env_var))\n",
        "    print(\"Should be {}\".format(path))\n",
        "    print(\"Variable is {}\".format(os.getenv(env_var)))\n",
        "  make_if_dont_exist(path, overwrite=False)\n",
        "\n",
        "print(\"If No Error Occured Continue Forward. =)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rIG4y9O25STU",
        "outputId": "75d722c3-d9cd-4e3d-fbac-b4ec6a263879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Please cite the following paper when using nnUNet:\n",
            "\n",
            "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
            "\n",
            "\n",
            "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
            "\n",
            "Colon Cancer Segmentation. \n",
            "Segmentation target are colon caner primaries, \n",
            "Input modalities are 0: CT scan. \n",
            "Also see Medical Segmentation Decathlon, http://medicaldecathlon.com/\n"
          ]
        }
      ],
      "source": [
        "!nnUNet_print_pretrained_model_info Task010_Colon\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrqKbzBOS4aJ",
        "outputId": "64961598-b0d5-4b3b-91f2-a70147f1a486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Please cite the following paper when using nnUNet:\n",
            "\n",
            "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
            "\n",
            "\n",
            "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
            "\n",
            "using model stored in  /content/drive/My Drive/Colab/RESULTS_FOLDER/nnUNet/3d_fullres/Task010_Colon/nnUNetTrainerV2__nnUNetPlansv2.1\n",
            "This model expects 1 input modalities for each image\n",
            "Found 1 unique case ids, here are some examples: ['ct_000']\n",
            "If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc\n",
            "number of cases: 1\n",
            "number of cases that still need to be predicted: 1\n",
            "emptying cuda cache\n",
            "loading parameters for folds, None\n",
            "folds is None so we will automatically look for output folders (not using 'all'!)\n",
            "found the following folds:  ['/content/drive/My Drive/Colab/RESULTS_FOLDER/nnUNet/3d_fullres/Task010_Colon/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0', '/content/drive/My Drive/Colab/RESULTS_FOLDER/nnUNet/3d_fullres/Task010_Colon/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1', '/content/drive/My Drive/Colab/RESULTS_FOLDER/nnUNet/3d_fullres/Task010_Colon/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2', '/content/drive/My Drive/Colab/RESULTS_FOLDER/nnUNet/3d_fullres/Task010_Colon/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3', '/content/drive/My Drive/Colab/RESULTS_FOLDER/nnUNet/3d_fullres/Task010_Colon/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4']\n",
            "2024-08-13 08:41:14.087744: Using dummy2d data augmentation\n",
            "using the following model files:  ['/content/drive/My Drive/Colab/RESULTS_FOLDER/nnUNet/3d_fullres/Task010_Colon/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model', '/content/drive/My Drive/Colab/RESULTS_FOLDER/nnUNet/3d_fullres/Task010_Colon/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_final_checkpoint.model', '/content/drive/My Drive/Colab/RESULTS_FOLDER/nnUNet/3d_fullres/Task010_Colon/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_final_checkpoint.model', '/content/drive/My Drive/Colab/RESULTS_FOLDER/nnUNet/3d_fullres/Task010_Colon/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3/model_final_checkpoint.model', '/content/drive/My Drive/Colab/RESULTS_FOLDER/nnUNet/3d_fullres/Task010_Colon/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4/model_final_checkpoint.model']\n",
            "starting preprocessing generator\n",
            "starting prediction...\n",
            "preprocessing OUTPUT_DIRECTORY/ct_000.nii.gz\n",
            "using preprocessor GenericPreprocessor\n",
            "before crop: (1, 431, 311, 311) after crop: (1, 431, 311, 311) spacing: [1.5 1.5 1.5] \n",
            "\n",
            "separate z, order in z is 0 order inplane is 3\n",
            "separate z, order in z is 0 order inplane is 1\n",
            "before: {'spacing': array([1.5, 1.5, 1.5]), 'spacing_transposed': array([1.5, 1.5, 1.5]), 'data.shape (data is transposed)': (1, 431, 311, 311)} \n",
            "after:  {'spacing': array([3.     , 0.78125, 0.78125]), 'data.shape (data is resampled)': (1, 216, 597, 597)} \n",
            "\n",
            "(1, 216, 597, 597)\n",
            "This worker has ended successfully, no errors to report\n",
            "predicting OUTPUT_DIRECTORY/ct_000.nii.gz\n",
            "debug: mirroring True mirror_axes (0, 1, 2)\n",
            "step_size: 0.5\n",
            "do mirror: True\n",
            "data shape: (1, 216, 597, 597)\n",
            "patch size: [ 56 192 160]\n",
            "steps (x, y, and z): [[0, 27, 53, 80, 107, 133, 160], [0, 81, 162, 243, 324, 405], [0, 73, 146, 218, 291, 364, 437]]\n",
            "number of tiles: 294\n",
            "computing Gaussian\n",
            "done\n",
            "prediction done\n",
            "debug: mirroring True mirror_axes (0, 1, 2)\n",
            "step_size: 0.5\n",
            "do mirror: True\n",
            "data shape: (1, 216, 597, 597)\n",
            "patch size: [ 56 192 160]\n",
            "steps (x, y, and z): [[0, 27, 53, 80, 107, 133, 160], [0, 81, 162, 243, 324, 405], [0, 73, 146, 218, 291, 364, 437]]\n",
            "number of tiles: 294\n",
            "using precomputed Gaussian\n",
            "prediction done\n",
            "debug: mirroring True mirror_axes (0, 1, 2)\n",
            "step_size: 0.5\n",
            "do mirror: True\n",
            "data shape: (1, 216, 597, 597)\n",
            "patch size: [ 56 192 160]\n",
            "steps (x, y, and z): [[0, 27, 53, 80, 107, 133, 160], [0, 81, 162, 243, 324, 405], [0, 73, 146, 218, 291, 364, 437]]\n",
            "number of tiles: 294\n",
            "using precomputed Gaussian\n",
            "prediction done\n",
            "debug: mirroring True mirror_axes (0, 1, 2)\n",
            "step_size: 0.5\n",
            "do mirror: True\n",
            "data shape: (1, 216, 597, 597)\n",
            "patch size: [ 56 192 160]\n",
            "steps (x, y, and z): [[0, 27, 53, 80, 107, 133, 160], [0, 81, 162, 243, 324, 405], [0, 73, 146, 218, 291, 364, 437]]\n",
            "number of tiles: 294\n",
            "using precomputed Gaussian\n",
            "prediction done\n",
            "debug: mirroring True mirror_axes (0, 1, 2)\n",
            "step_size: 0.5\n",
            "do mirror: True\n",
            "data shape: (1, 216, 597, 597)\n",
            "patch size: [ 56 192 160]\n",
            "steps (x, y, and z): [[0, 27, 53, 80, 107, 133, 160], [0, 81, 162, 243, 324, 405], [0, 73, 146, 218, 291, 364, 437]]\n",
            "number of tiles: 294\n",
            "using precomputed Gaussian\n",
            "prediction done\n",
            "inference done. Now waiting for the segmentation export to finish...\n",
            "force_separate_z: None interpolation order: 1\n",
            "separate z: True lowres axis [0]\n",
            "separate z, order in z is 0 order inplane is 1\n",
            "postprocessing...\n"
          ]
        }
      ],
      "source": [
        "!nnUNet_predict -i \"$nnUNet_raw_data_base/Dataset001_TestSet/imagesTr/\" -o OUTPUT_DIRECTORY -t Task010_Colon -m 3d_fullres\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}